{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532aa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import meerkat as mk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from domino.utils import unpack_args\n",
    "\n",
    "from abstract import Slicer\n",
    "from sklearn import mixture\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ced952",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1005169444.py, line 156)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/rb/jmqwn68s2t3g0k5scvtpf1hm0000gr/T/ipykernel_3478/1005169444.py\"\u001b[0;36m, line \u001b[0;32m156\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PlaneSpotSlicer(Slicer):\n",
    "    r\"\"\"\n",
    "    Implements PlaneSpot [plumb_2023], a simple SDM that fits a GMM to a 2D model \n",
    "    embedding, fit using scvis [ding_2018]. \n",
    "\n",
    "    ..  [plumb_2023]\n",
    "        Gregory Plumb*, Nari Johnson*, Ángel Alexander Cabrera, Ameet Talwalkar.\n",
    "        Towards a More Rigorous Science of Blindspot Discovery in Image \n",
    "        Classification Models. arXiv:2207.04104 [cs] (2023)\n",
    "        \n",
    "    ..  [ding_2018]\n",
    "        Jiarui Ding, Anne Condon, and Sohrab P Shah. \n",
    "        Interpretable dimensionality reduction of single cell transcriptome \n",
    "        data with deep generative models. \n",
    "        Nature communications, 9(1):1–13. (2018)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_slices: int = 10,\n",
    "        n_max_mixture_components: int = 33, # maximum number of mixture components\n",
    "        weight: float = 0.025, # weight hyperparameter\n",
    "        scvis_config_path = None, # custom scvis config path\n",
    "        scvis_output_dir = 'scvis' # path to output directory for scvis\n",
    "    ):\n",
    "        super().__init__(n_slices=n_slices)\n",
    "\n",
    "        self.config.scvis_config_path = scvis_config_path\n",
    "        self.config.scvis_output_dir = scvis_output_dir\n",
    "        \n",
    "        self.config.n_max_mixture_components = n_max_mixture_components\n",
    "        self.config.weight = weight\n",
    "\n",
    "        self.gmm = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "        verbose: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "        \n",
    "        embeddings, targets, pred_probs = convert_to_numpy(\n",
    "            embeddings, targets, pred_probs\n",
    "        )\n",
    "        \n",
    "        # 1.  Fit scvis.\n",
    "        if verbose:\n",
    "            print('Fitting scvis...')\n",
    "        \n",
    "        scvis_embeddings = self._fit_scvis(embeddings)\n",
    "        \n",
    "        # 2.  Fit GMM.\n",
    "        if verbose:\n",
    "            print('Fitting GMM...')\n",
    "            \n",
    "        self._fit_gmm(scvis_embeddings,\n",
    "                     pred_probs)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "\n",
    "        losses = self._compute_losses(\n",
    "            pred_probs=pred_probs, targets=targets, losses=losses\n",
    "        )\n",
    "        embeddings = torch.tensor(embeddings).to(\n",
    "            dtype=torch.float, device=self.config.device\n",
    "        )\n",
    "\n",
    "        all_weights = []\n",
    "\n",
    "        for slice_idx in range(self.config.n_slices):\n",
    "            weights, _, _, _ = md_adversary_weights(\n",
    "                mean=self.means[slice_idx],\n",
    "                precision=torch.exp(self.precisions[slice_idx])\n",
    "                * torch.eye(self.means[slice_idx].shape[0], device=self.config.device),\n",
    "                x=embeddings,\n",
    "                losses=losses,\n",
    "            )\n",
    "            all_weights.append(weights.cpu().numpy())\n",
    "        return np.stack(all_weights, axis=1)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        data: mk.DataPanel,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        probs = self.predict_proba(\n",
    "            data=data,\n",
    "            embeddings=embeddings,\n",
    "            targets=targets,\n",
    "            pred_probs=pred_probs,\n",
    "            losses=losses,\n",
    "        )\n",
    "\n",
    "        # TODO (Greg): check if this is the preferred way to get hard predictions from\n",
    "        # probabilities\n",
    "        return (probs > 0.5).astype(np.int32)\n",
    "\n",
    "    def _fit_scvis(\n",
    "        self, embeddings: np.ndarray\n",
    "    ):\n",
    "        ''' Fits an scvis model to the input embedding(s).\n",
    "        '''\n",
    "        # Make output directory\n",
    "        os.system(f'rm -rf {self.config.scvis_output_dir}')\n",
    "        os.system(f'mkdir {self.config.scvis_output_dir}')\n",
    "    \n",
    "        # Dump the embeddings as a CSV file\n",
    "        embedding_filepath = f'{self.config.scvis_output_dir}/tmp.tsv'\n",
    "        embedding_df = pd.DataFrame(reps)\n",
    "        embedding_df.to_csv(embedding_filepath, sep = '\\t', index = False)\n",
    "\n",
    "        # Run scvis using the command line\n",
    "        # source: https://github.com/shahcompbio/scvis\n",
    "        command = f'scvis train --data_matrix_file {out_tmp} --out_dir {base_dir}'\n",
    "        \n",
    "        if scvis_config_path is not None:\n",
    "            # Add optional scvis config\n",
    "            command += f' --config_file {self.config.scvis_config_path}'\n",
    "            \n",
    "        # Run the command (blocking)\n",
    "        os.system(command)\n",
    "        \n",
    "        # Cleanup\n",
    "        os.system('rm -rf {}'.format(out_tmp))\n",
    "        \n",
    "        # Load and return the scvis embeddings\n",
    "        search_string = f'{self.config.scvis_output_dir}/*.tsv'\n",
    "        scvis_embedding_filepath = sorted(glob.glob(search_string), key = len)[0]\n",
    "        return pd.read_csv(scvis_embedding_filepath, sep = '\\t', index_col = 0).values\n",
    "    \n",
    "    def _fit_gmm(\n",
    "        self, reduced_embeddings: np.ndarray, pred_prbs: np.ndarray\n",
    "    )\n",
    "        # Normalize the embeddings to have range [0, 1]\n",
    "        X = np.copy(embedding)\n",
    "        X -= np.min(X, axis = 0)\n",
    "        X /= np.max(X, axis = 0)\n",
    "        \n",
    "        # Append (weighted) predicted probabilities to the embedding\n",
    "        X = np.concatenate((X, error_weight * pred_prbs.reshape(-1, 1)), axis = 1)\n",
    "        \n",
    "        lowest_bic = np.infty\n",
    "        bic = []\n",
    "        n_components_range = range(1, self.config.n_max_mixture_components)\n",
    "\n",
    "        for n_components in n_components_range:\n",
    "            gmm = mixture.GaussianMixture(n_components = n_components, covariance_type = 'full')\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ab9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm-camera",
   "language": "python",
   "name": "bdm-camera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
