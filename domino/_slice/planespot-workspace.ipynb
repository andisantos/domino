{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60ef40e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Notebook workspace for PlaneSpotSlicer.\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "* install scvis using this package: https://github.com/shahcompbio/scvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532aa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import meerkat as mk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from domino.utils import unpack_args\n",
    "\n",
    "from abstract import Slicer\n",
    "from sklearn import mixture\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46ced952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import meerkat as mk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from domino.utils import unpack_args\n",
    "\n",
    "from abstract import Slicer\n",
    "\n",
    "## PlaneSpot imports\n",
    "from sklearn import mixture\n",
    "import glob\n",
    "\n",
    "from domino.utils import convert_to_numpy, unpack_args\n",
    "import pandas as pd\n",
    "\n",
    "class PlaneSpotSlicer(Slicer):\n",
    "    r\"\"\"\n",
    "    Implements PlaneSpot [plumb_2023], a simple SDM that fits a GMM to a 2D model \n",
    "    embedding, fit using scvis [ding_2018]. \n",
    "\n",
    "    ..  [plumb_2023]\n",
    "        Gregory Plumb*, Nari Johnson*, Ángel Alexander Cabrera, Ameet Talwalkar.\n",
    "        Towards a More Rigorous Science of Blindspot Discovery in Image \n",
    "        Classification Models. arXiv:2207.04104 [cs] (2023)\n",
    "        \n",
    "    ..  [ding_2018]\n",
    "        Jiarui Ding, Anne Condon, and Sohrab P Shah. \n",
    "        Interpretable dimensionality reduction of single cell transcriptome \n",
    "        data with deep generative models. \n",
    "        Nature communications, 9(1):1–13. (2018)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        scvis_conda_env: str, # name of conda environment where scvis is installed\n",
    "        n_slices: int = 10,\n",
    "        n_max_mixture_components: int = 33, # maximum number of mixture components\n",
    "        weight: float = 0.025, # weight hyperparameter\n",
    "        scvis_config_path = None, # custom scvis config path\n",
    "        scvis_output_dir = 'scvis', # path to output directory for scvis\n",
    "        fit_scvis = True # flag to load rather than re-compute the scvis embedding \n",
    "    ):\n",
    "        super().__init__(n_slices=n_slices)\n",
    "        \n",
    "        # scvis hyper-parameters\n",
    "        self.scvis_conda_env = scvis_conda_env\n",
    "        self.config.scvis_config_path = scvis_config_path\n",
    "        self.config.scvis_output_dir = scvis_output_dir\n",
    "        self.fit_scvis = fit_scvis\n",
    "        \n",
    "        # GMM hyper-parameters\n",
    "        self.config.n_max_mixture_components = n_max_mixture_components\n",
    "        self.config.weight = weight\n",
    "\n",
    "        self.gmm = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "        verbose: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "        \n",
    "        embeddings, targets, pred_probs = convert_to_numpy(\n",
    "            embeddings, targets, pred_probs\n",
    "        )\n",
    "        \n",
    "        # 1.  Fit scvis.\n",
    "        if verbose:\n",
    "            print('Fitting scvis...')\n",
    "        \n",
    "        scvis_embeddings = self._fit_scvis(embeddings.reshape(embeddings.shape[0], embeddings.shape[1]))\n",
    "        \n",
    "        # 2.  Fit GMM.\n",
    "        if verbose:\n",
    "            print('Fitting GMM...')\n",
    "            \n",
    "        self._fit_gmm(scvis_embeddings,\n",
    "                     pred_probs)\n",
    "\n",
    "    def predict_proba(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "\n",
    "        losses = self._compute_losses(\n",
    "            pred_probs=pred_probs, targets=targets, losses=losses\n",
    "        )\n",
    "        embeddings = torch.tensor(embeddings).to(\n",
    "            dtype=torch.float, device=self.config.device\n",
    "        )\n",
    "\n",
    "        all_weights = []\n",
    "\n",
    "        for slice_idx in range(self.config.n_slices):\n",
    "            weights, _, _, _ = md_adversary_weights(\n",
    "                mean=self.means[slice_idx],\n",
    "                precision=torch.exp(self.precisions[slice_idx])\n",
    "                * torch.eye(self.means[slice_idx].shape[0], device=self.config.device),\n",
    "                x=embeddings,\n",
    "                losses=losses,\n",
    "            )\n",
    "            all_weights.append(weights.cpu().numpy())\n",
    "        return np.stack(all_weights, axis=1)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        data: mk.DataPanel,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        probs = self.predict_proba(\n",
    "            data=data,\n",
    "            embeddings=embeddings,\n",
    "            targets=targets,\n",
    "            pred_probs=pred_probs,\n",
    "            losses=losses,\n",
    "        )\n",
    "\n",
    "        # TODO (Greg): check if this is the preferred way to get hard predictions from\n",
    "        # probabilities\n",
    "        return (probs > 0.5).astype(np.int32)\n",
    "\n",
    "    def _fit_scvis(\n",
    "        self, embeddings: np.ndarray\n",
    "    ):\n",
    "        ''' Fits an scvis model to the input embedding(s).\n",
    "        '''\n",
    "        if self.fit_scvis:\n",
    "            ### Fit scvis\n",
    "            \n",
    "            # Make output directory\n",
    "            os.system(f'rm -rf {self.config.scvis_output_dir}')\n",
    "            os.system(f'mkdir {self.config.scvis_output_dir}')\n",
    "\n",
    "            # Dump the embeddings as a CSV file\n",
    "            embedding_filepath = f'{self.config.scvis_output_dir}/tmp.tsv'\n",
    "            embedding_df = pd.DataFrame(embeddings)\n",
    "            embedding_df.to_csv(embedding_filepath, sep = '\\t', index = False)\n",
    "\n",
    "            # Run scvis using the command line\n",
    "            # source: https://github.com/shahcompbio/scvis\n",
    "            command = f'conda run -n {self.scvis_conda_env} scvis train --data_matrix_file {embedding_filepath} --out_dir {self.config.scvis_output_dir}'\n",
    "\n",
    "            if self.config.scvis_config_path is not None:\n",
    "                print(self.config.scvis_config_path)\n",
    "                # Add optional scvis config\n",
    "                command += f' --config_file {self.config.scvis_config_path}'\n",
    "\n",
    "            # Run the command (blocking)\n",
    "            print(command)\n",
    "            os.system(command)\n",
    "            print('done')\n",
    "\n",
    "            # Cleanup\n",
    "            os.system('rm -rf {}'.format(embedding_filepath))\n",
    "        \n",
    "        ### Load and return the scvis embeddings\n",
    "        search_string = f'{self.config.scvis_output_dir}/*.tsv'\n",
    "        scvis_embedding_filepath = sorted(glob.glob(search_string), key = len)[0]\n",
    "        return pd.read_csv(scvis_embedding_filepath, sep = '\\t', index_col = 0).values\n",
    "    \n",
    "    def _fit_gmm(\n",
    "        self, reduced_embeddings: np.ndarray, pred_prbs: np.ndarray\n",
    "    ):\n",
    "        # Normalize the embeddings to have range [0, 1]\n",
    "        X = np.copy(reduced_embeddings)\n",
    "        X -= np.min(X, axis = 0)\n",
    "        X /= np.max(X, axis = 0)\n",
    "        \n",
    "        # Append (weighted) predicted probabilities to the embedding\n",
    "        X = np.concatenate((X, self.config.weight * pred_prbs.reshape(-1, 1)), axis = 1)\n",
    "        \n",
    "        lowest_bic = np.infty\n",
    "        bic = []\n",
    "        n_components_range = range(self.config.n_slices, self.config.n_max_mixture_components)\n",
    "\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a GMM with n_components components\n",
    "            gmm = mixture.GaussianMixture(n_components = n_components, covariance_type = 'full')\n",
    "            gmm.fit(X)\n",
    "            \n",
    "            # Calculate the Bayesian Information Criteria\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "                \n",
    "        self.gmm = best_gmm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1fe01",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "(copied from `examples/01_intro.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b319004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dp = mk.datasets.get(\"imagenette\")\n",
    "\n",
    "# we'll only be using the validation data\n",
    "dp = dp.lz[dp[\"split\"] == \"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a400423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torchvision.transforms as transforms\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5546f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d344388c78498ab2ba88ac0ce4f53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 2. Create new column with transform \n",
    "dp[\"input\"] = dp[\"img\"].to_lambda(transform)\n",
    "\n",
    "# 1. Move the model to device\n",
    "DEVICE = 'cpu'\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# 2. Define a function that runs a forward pass over a batch \n",
    "@torch.no_grad()\n",
    "def predict(batch: mk.DataPanel):\n",
    "    input_col: mk.TensorColumn = batch[\"input\"] \n",
    "    x: torch.Tensor = input_col.data.to(DEVICE)  # We get the underlying torch tensor with `data` and move to GPU \n",
    "    out: torch.Tensor = model(x)  # Run forward pass\n",
    "\n",
    "    # Return a dictionary with one key for each of the new columns. Each value in the\n",
    "    # dictionary should have the same length as the batch. \n",
    "    return {\n",
    "        \"pred\": out.cpu().numpy().argmax(axis=-1),\n",
    "        \"probs\": torch.softmax(out, axis=-1).cpu().numpy(),\n",
    "    }\n",
    "\n",
    "# 3. Apply the update. Note that the `predict` function operates on batches, so we set \n",
    "# `is_batched_fn=True`. Also, the `predict` function only accesses the \"input\" column, by \n",
    "# specifying that here we instruct update to only load that one column and skip others \n",
    "dp = dp.update(\n",
    "    function=predict,\n",
    "    is_batched_fn=True,\n",
    "    batch_size=32,\n",
    "    input_columns=[\"input\"], \n",
    "    pbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3706b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro accuracy across the ten Imagenette classes: 0.672\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "import hashlib\n",
    "x = \"helo\"\n",
    "int.from_bytes(hashlib.sha256(x.encode('utf-8')).digest(), 'big') % 100\n",
    "\n",
    "dp[\"correct\"] = dp[\"pred\"] == mk.NumpyArrayColumn(dp[\"label_idx\"])\n",
    "accuracy = dp[\"correct\"].mean()\n",
    "print(f\"Micro accuracy across the ten Imagenette classes: {accuracy:0.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb9055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a single ImageNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc40df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_IDX = 571\n",
    "\n",
    "# convert to a binary task \n",
    "dp[\"prob\"] = dp[\"probs\"][:, LABEL_IDX]\n",
    "dp[\"target\"] = (dp[\"label_idx\"] == LABEL_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26af85",
   "metadata": {},
   "source": [
    "## 1. Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374cd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, requires_grad = None):\n",
    "        self.features = None\n",
    "        self.requires_grad = requires_grad\n",
    "        \n",
    "    def __call__(self, modules, module_in, module_out):\n",
    "        if self.requires_grad is not None:\n",
    "            module_out.requires_grad = self.requires_grad\n",
    "        self.features = module_out\n",
    "        \n",
    "# Register feature hook\n",
    "feature_hook = Features()\n",
    "handle = list(model.modules())[66].register_forward_hook(feature_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c9df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last-layer embeddings from the model, and add them as the \"embedding\" column.\n",
    "\n",
    "def last_layer(batch: mk.DataPanel):\n",
    "    input_col: mk.TensorColumn = batch[\"input\"] \n",
    "    x: torch.Tensor = input_col.data.to(DEVICE)  # We get the underlying torch tensor with `data` and move to GPU \n",
    "    \n",
    "    ## add a hook to the model\n",
    "    out: torch.Tensor = model(x)  # Run forward pass\n",
    "    features: np.ndarray = feature_hook.features.data.cpu().numpy()\n",
    "\n",
    "    # Return a dictionary with one key for each of the new columns. Each value in the\n",
    "    # dictionary should have the same length as the batch. \n",
    "    return {\n",
    "        \"embedding\": features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465a3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497bb7892a6248f686893841c5b705cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp = dp.update(\n",
    "    function=last_layer,\n",
    "    is_batched_fn=True,\n",
    "    batch_size=32,\n",
    "    input_columns=[\"input\"], \n",
    "    pbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aac199",
   "metadata": {},
   "source": [
    "# 2. Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55757ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "planespot = PlaneSpotSlicer(scvis_conda_env = 'scvis',\n",
    "                           fit_scvis = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cc65f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting scvis...\n",
      "Fitting GMM...\n"
     ]
    }
   ],
   "source": [
    "planespot.fit(data = dp, embeddings=\"embedding\", targets=\"target\", pred_probs=\"prob\")\n",
    "\n",
    "# dp[\"planespot_slices\"] = .predict_proba(\n",
    "#     data=dp, embeddings=\"clip(img)\", targets=\"target\", pred_probs=\"prob\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f7ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm-camera",
   "language": "python",
   "name": "bdm-camera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
