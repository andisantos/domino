{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532aa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import meerkat as mk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from domino.utils import unpack_args\n",
    "\n",
    "from abstract import Slicer\n",
    "from sklearn import mixture\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ced952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import meerkat as mk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from domino.utils import unpack_args\n",
    "\n",
    "from abstract import Slicer\n",
    "\n",
    "## PlaneSpot imports\n",
    "from sklearn import mixture\n",
    "import glob\n",
    "\n",
    "class PlaneSpotSlicer(Slicer):\n",
    "    r\"\"\"\n",
    "    Implements PlaneSpot [plumb_2023], a simple SDM that fits a GMM to a 2D model \n",
    "    embedding, fit using scvis [ding_2018]. \n",
    "\n",
    "    ..  [plumb_2023]\n",
    "        Gregory Plumb*, Nari Johnson*, Ángel Alexander Cabrera, Ameet Talwalkar.\n",
    "        Towards a More Rigorous Science of Blindspot Discovery in Image \n",
    "        Classification Models. arXiv:2207.04104 [cs] (2023)\n",
    "        \n",
    "    ..  [ding_2018]\n",
    "        Jiarui Ding, Anne Condon, and Sohrab P Shah. \n",
    "        Interpretable dimensionality reduction of single cell transcriptome \n",
    "        data with deep generative models. \n",
    "        Nature communications, 9(1):1–13. (2018)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_slices: int = 10,\n",
    "        n_max_mixture_components: int = 33, # maximum number of mixture components\n",
    "        weight: float = 0.025, # weight hyperparameter\n",
    "        scvis_config_path = None, # custom scvis config path\n",
    "        scvis_output_dir = 'scvis' # path to output directory for scvis\n",
    "    ):\n",
    "        super().__init__(n_slices=n_slices)\n",
    "\n",
    "        self.config.scvis_config_path = scvis_config_path\n",
    "        self.config.scvis_output_dir = scvis_output_dir\n",
    "        \n",
    "        self.config.n_max_mixture_components = n_max_mixture_components\n",
    "        self.config.weight = weight\n",
    "\n",
    "        self.gmm = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "        verbose: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "        \n",
    "        embeddings, targets, pred_probs = convert_to_numpy(\n",
    "            embeddings, targets, pred_probs\n",
    "        )\n",
    "        \n",
    "        # 1.  Fit scvis.\n",
    "        if verbose:\n",
    "            print('Fitting scvis...')\n",
    "        \n",
    "        scvis_embeddings = self._fit_scvis(embeddings)\n",
    "        \n",
    "        # 2.  Fit GMM.\n",
    "        if verbose:\n",
    "            print('Fitting GMM...')\n",
    "            \n",
    "        self._fit_gmm(scvis_embeddings,\n",
    "                     pred_probs)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(\n",
    "        self,\n",
    "        data: Union[dict, mk.DataPanel] = None,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        embeddings, targets, pred_probs, losses = unpack_args(\n",
    "            data, embeddings, targets, pred_probs, losses\n",
    "        )\n",
    "\n",
    "        losses = self._compute_losses(\n",
    "            pred_probs=pred_probs, targets=targets, losses=losses\n",
    "        )\n",
    "        embeddings = torch.tensor(embeddings).to(\n",
    "            dtype=torch.float, device=self.config.device\n",
    "        )\n",
    "\n",
    "        all_weights = []\n",
    "\n",
    "        for slice_idx in range(self.config.n_slices):\n",
    "            weights, _, _, _ = md_adversary_weights(\n",
    "                mean=self.means[slice_idx],\n",
    "                precision=torch.exp(self.precisions[slice_idx])\n",
    "                * torch.eye(self.means[slice_idx].shape[0], device=self.config.device),\n",
    "                x=embeddings,\n",
    "                losses=losses,\n",
    "            )\n",
    "            all_weights.append(weights.cpu().numpy())\n",
    "        return np.stack(all_weights, axis=1)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        data: mk.DataPanel,\n",
    "        embeddings: Union[str, np.ndarray] = \"embedding\",\n",
    "        targets: Union[str, np.ndarray] = None,\n",
    "        pred_probs: Union[str, np.ndarray] = None,\n",
    "        losses: Union[str, np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        probs = self.predict_proba(\n",
    "            data=data,\n",
    "            embeddings=embeddings,\n",
    "            targets=targets,\n",
    "            pred_probs=pred_probs,\n",
    "            losses=losses,\n",
    "        )\n",
    "\n",
    "        # TODO (Greg): check if this is the preferred way to get hard predictions from\n",
    "        # probabilities\n",
    "        return (probs > 0.5).astype(np.int32)\n",
    "\n",
    "    def _fit_scvis(\n",
    "        self, embeddings: np.ndarray\n",
    "    ):\n",
    "        ''' Fits an scvis model to the input embedding(s).\n",
    "        '''\n",
    "        # Make output directory\n",
    "        os.system(f'rm -rf {self.config.scvis_output_dir}')\n",
    "        os.system(f'mkdir {self.config.scvis_output_dir}')\n",
    "    \n",
    "        # Dump the embeddings as a CSV file\n",
    "        embedding_filepath = f'{self.config.scvis_output_dir}/tmp.tsv'\n",
    "        embedding_df = pd.DataFrame(reps)\n",
    "        embedding_df.to_csv(embedding_filepath, sep = '\\t', index = False)\n",
    "\n",
    "        # Run scvis using the command line\n",
    "        # source: https://github.com/shahcompbio/scvis\n",
    "        command = f'scvis train --data_matrix_file {out_tmp} --out_dir {base_dir}'\n",
    "        \n",
    "        if scvis_config_path is not None:\n",
    "            # Add optional scvis config\n",
    "            command += f' --config_file {self.config.scvis_config_path}'\n",
    "            \n",
    "        # Run the command (blocking)\n",
    "        os.system(command)\n",
    "        \n",
    "        # Cleanup\n",
    "        os.system('rm -rf {}'.format(out_tmp))\n",
    "        \n",
    "        # Load and return the scvis embeddings\n",
    "        search_string = f'{self.config.scvis_output_dir}/*.tsv'\n",
    "        scvis_embedding_filepath = sorted(glob.glob(search_string), key = len)[0]\n",
    "        return pd.read_csv(scvis_embedding_filepath, sep = '\\t', index_col = 0).values\n",
    "    \n",
    "    def _fit_gmm(\n",
    "        self, reduced_embeddings: np.ndarray, pred_prbs: np.ndarray\n",
    "    ):\n",
    "        # Normalize the embeddings to have range [0, 1]\n",
    "        X = np.copy(embedding)\n",
    "        X -= np.min(X, axis = 0)\n",
    "        X /= np.max(X, axis = 0)\n",
    "        \n",
    "        # Append (weighted) predicted probabilities to the embedding\n",
    "        X = np.concatenate((X, error_weight * pred_prbs.reshape(-1, 1)), axis = 1)\n",
    "        \n",
    "        lowest_bic = np.infty\n",
    "        bic = []\n",
    "        n_components_range = range(1, self.config.n_max_mixture_components)\n",
    "\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a GMM with n_components components\n",
    "            gmm = mixture.GaussianMixture(n_components = n_components, covariance_type = 'full')\n",
    "            gmm.fit(X)\n",
    "            \n",
    "            # Calculate the Bayesian Information Criteria\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "                \n",
    "        self.gmm = best_gmm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1fe01",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b319004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to /Users/narij/.meerkat/datasets/imagenette/imagenette2-160.tgz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983d7ad3f56b4a569c9c7299529ff854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99003388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar archive, this may take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dp = mk.datasets.get(\"imagenette\")\n",
    "\n",
    "# we'll only be using the validation data\n",
    "dp = dp.lz[dp[\"split\"] == \"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a400423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/narij/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adaf2f6654c4822ad60c18c64ab80e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torchvision.transforms as transforms\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f5546f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca4b093dda14d5680c7bbda41ef3f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 2. Create new column with transform \n",
    "dp[\"input\"] = dp[\"img\"].to_lambda(transform)\n",
    "\n",
    "# 1. Move the model to device\n",
    "DEVICE = 'cpu'\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# 2. Define a function that runs a forward pass over a batch \n",
    "@torch.no_grad()\n",
    "def predict(batch: mk.DataPanel):\n",
    "    input_col: mk.TensorColumn = batch[\"input\"] \n",
    "    x: torch.Tensor = input_col.data.to(DEVICE)  # We get the underlying torch tensor with `data` and move to GPU \n",
    "    out: torch.Tensor = model(x)  # Run forward pass\n",
    "\n",
    "    # Return a dictionary with one key for each of the new columns. Each value in the\n",
    "    # dictionary should have the same length as the batch. \n",
    "    return {\n",
    "        \"pred\": out.cpu().numpy().argmax(axis=-1),\n",
    "        \"probs\": torch.softmax(out, axis=-1).cpu().numpy(),\n",
    "    }\n",
    "\n",
    "# 3. Apply the update. Note that the `predict` function operates on batches, so we set \n",
    "# `is_batched_fn=True`. Also, the `predict` function only accesses the \"input\" column, by \n",
    "# specifying that here we instruct update to only load that one column and skip others \n",
    "dp = dp.update(\n",
    "    function=predict,\n",
    "    is_batched_fn=True,\n",
    "    batch_size=32,\n",
    "    input_columns=[\"input\"], \n",
    "    pbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3706b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro accuracy across the ten Imagenette classes: 0.672\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "import hashlib\n",
    "x = \"helo\"\n",
    "int.from_bytes(hashlib.sha256(x.encode('utf-8')).digest(), 'big') % 100\n",
    "\n",
    "dp[\"correct\"] = dp[\"pred\"] == mk.NumpyArrayColumn(dp[\"label_idx\"])\n",
    "accuracy = dp[\"correct\"].mean()\n",
    "print(f\"Micro accuracy across the ten Imagenette classes: {accuracy:0.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26af85",
   "metadata": {},
   "source": [
    "## 1. Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "374cd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, requires_grad = None):\n",
    "        self.features = None\n",
    "        self.requires_grad = requires_grad\n",
    "        \n",
    "    def __call__(self, modules, module_in, module_out):\n",
    "        if self.requires_grad is not None:\n",
    "            module_out.requires_grad = self.requires_grad\n",
    "        self.features = module_out\n",
    "        \n",
    "# Register feature hook\n",
    "feature_hook = Features()\n",
    "handle = list(model.modules())[66].register_forward_hook(feature_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c9df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last-layer embeddings from the model, and add them as the \"embedding\" column.\n",
    "\n",
    "def last_layer(batch: mk.DataPanel):\n",
    "    input_col: mk.TensorColumn = batch[\"input\"] \n",
    "    x: torch.Tensor = input_col.data.to(DEVICE)  # We get the underlying torch tensor with `data` and move to GPU \n",
    "    \n",
    "    ## add a hook to the model\n",
    "    out: torch.Tensor = model(x)  # Run forward pass\n",
    "    features: np.ndarray = feature_hook.features.data.cpu().numpy()\n",
    "\n",
    "    # Return a dictionary with one key for each of the new columns. Each value in the\n",
    "    # dictionary should have the same length as the batch. \n",
    "    return {\n",
    "        \"embedding\": features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "465a3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17b36b0cd6543938123448f1fcc1cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp = dp.update(\n",
    "    function=last_layer,\n",
    "    is_batched_fn=True,\n",
    "    batch_size=32,\n",
    "    input_columns=[\"input\"], \n",
    "    pbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aac199",
   "metadata": {},
   "source": [
    "# 2. Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55757ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "planespot = PlaneSpotSlicer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "658cc65f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column `target` does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rb/jmqwn68s2t3g0k5scvtpf1hm0000gr/T/ipykernel_8114/1202655374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplanespot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dp[\"planespot_slices\"] = .predict_proba(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     data=dp, embeddings=\"clip(img)\", targets=\"target\", pred_probs=\"prob\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rb/jmqwn68s2t3g0k5scvtpf1hm0000gr/T/ipykernel_8114/287853449.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, embeddings, targets, pred_probs, losses, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     ):\n\u001b[0;32m---> 63\u001b[0;31m         embeddings, targets, pred_probs, losses = unpack_args(\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         )\n",
      "\u001b[0;32m~/Documents/domino/domino/utils.py\u001b[0m in \u001b[0;36munpack_args\u001b[0;34m(data, *args)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbstractColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# this is necessary because torch.tensor() of a NumpyArrayColumn is very\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/meerkat/datapanel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# @capture_provenance(capture_args=[])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaterialize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/meerkat/datapanel.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, index, materialize)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column `{index}` does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column `target` does not exist.'"
     ]
    }
   ],
   "source": [
    "planespot.fit(data = dp, embeddings=\"embedding\", targets=\"target\", pred_probs=\"prob\")\n",
    "\n",
    "# dp[\"planespot_slices\"] = .predict_proba(\n",
    "#     data=dp, embeddings=\"clip(img)\", targets=\"target\", pred_probs=\"prob\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f7ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm-camera",
   "language": "python",
   "name": "bdm-camera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
