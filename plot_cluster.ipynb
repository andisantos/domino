{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601a5007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51655 images from 1 classes.\n",
      "    Class 'bathroom' (0): 51655 images.\n",
      "Found 100012 images from 1 classes.\n",
      "    Class 'bedroom' (1): 100012 images.\n",
      "Found 41849 images from 1 classes.\n",
      "    Class 'childs_room' (2): 41849 images.\n",
      "Found 33763 images from 1 classes.\n",
      "    Class 'classroom' (3): 33763 images.\n",
      "Found 21889 images from 1 classes.\n",
      "    Class 'dressing_room' (4): 21889 images.\n",
      "Found 89458 images from 1 classes.\n",
      "    Class 'living_room' (5): 89458 images.\n",
      "Found 12633 images from 1 classes.\n",
      "    Class 'studio' (6): 12633 images.\n",
      "Found 13547 images from 1 classes.\n",
      "    Class 'swimming_pool' (7): 13547 images.\n",
      "\n",
      "Dataloader: 1 batch size | 51655 batches | 51655 images\n",
      "\n",
      "Dataloader: 1 batch size | 100012 batches | 100012 images\n",
      "\n",
      "Dataloader: 1 batch size | 41849 batches | 41849 images\n",
      "\n",
      "Dataloader: 1 batch size | 33763 batches | 33763 images\n",
      "\n",
      "Dataloader: 1 batch size | 21889 batches | 21889 images\n",
      "\n",
      "Dataloader: 1 batch size | 89458 batches | 89458 images\n",
      "\n",
      "Dataloader: 1 batch size | 12633 batches | 12633 images\n",
      "\n",
      "Dataloader: 1 batch size | 13547 batches | 13547 images\n"
     ]
    }
   ],
   "source": [
    "from dataloader_places import PlacesDataset\n",
    "from dataloader_pacs import Dataloader_PACS\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from plot_mosaic import PlotMosaic\n",
    "\n",
    "plot = PlotMosaic(img_size=64)\n",
    "\n",
    "# # PACS\n",
    "# dataset = Dataloader_PACS()\n",
    "# dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "# datasetname = 'PACS'\n",
    "\n",
    "# PLACES 8\n",
    "idx_to_classname ={0: 'bathroom', 1: 'bedroom', 2: 'childs_room',\n",
    "                   3: 'classroom', 4: 'dressing_room', 5: 'living_room',\n",
    "                   6: 'studio', 7: \"swimming_pool\"}\n",
    "\n",
    "data_path = \"../adversarial-sets/data/Places8_paths_and_labels_complete_train.npy\"\n",
    "\n",
    "places_ds = [PlacesDataset(data_path,\n",
    "                           onlylabels=[k]) for k in range(8)]\n",
    "batch_size = 1\n",
    "train_dataloaders_class = {k: DataLoader(places_ds[k],\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=8) for k in range(8)}\n",
    "for k in range(8):\n",
    "    print(f\"\\nDataloader: {batch_size} batch size | {len(train_dataloaders_class[k])} batches | {len(train_dataloaders_class[k].dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a90965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51655\n",
      "100012\n",
      "41849\n",
      "33763\n",
      "21889\n",
      "89458\n",
      "12633\n",
      "13547\n"
     ]
    }
   ],
   "source": [
    "# Places8\n",
    "csvs = ['outputs/class0_bathroom_2slices_binarytargets.csv', 'outputs/class1_bedroom_2slices_binarytargets.csv',\n",
    "        'outputs/class2_childsroom_2slices_binarytargets.csv', 'outputs/class3_classroom_2slices_binarytargets.csv',\n",
    "        'outputs/class4_dressingroom_2slices_binarytargets.csv', 'outputs/class5_livingroom_2slices_binarytargets.csv',\n",
    "       'outputs/class6_studio_2slices_binarytargets.csv', 'outputs/class7_swimmingpool_2slices_binarytargets.csv']\n",
    "\n",
    "# PACS\n",
    "# csvs = ['outputs/PACS_class0_4slices_binarytargets.csv', 'outputs/PACS_class1_4slices_binarytargets.csv',\n",
    "#        'outputs/PACS_class2_4slices_binarytargets.csv', 'outputs/PACS_class3_4slices_binarytargets.csv',\n",
    "#        'outputs/PACS_class4_4slices_binarytargets.csv', 'outputs/PACS_class5_4slices_binarytargets.csv',\n",
    "#        'outputs/PACS_class6_4slices_binarytargets.csv']\n",
    "\n",
    "\n",
    "for idx, csv_file in enumerate(csvs):\n",
    "    df = pd.read_csv(csv_file, index_col=[0])\n",
    "    df = df.iloc[:, 0]\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, csv_file in enumerate(csvs):\n",
    "#     df = pd.read_csv(csv_file, index_col=[0])\n",
    "#     df = df.iloc[:, 0]\n",
    "    \n",
    "#     image_list_cluster0 = []\n",
    "#     image_list_cluster1 = []\n",
    "\n",
    "#     for idx2, element in enumerate(train_dataloaders_class[idx]):\n",
    "#         if df[idx2] == 0:\n",
    "#             image_list_cluster1.append(plot.img_reshape(element[2][0], 28))\n",
    "#         else: \n",
    "#             image_list_cluster0.append(plot.img_reshape(element[2][0], 28))\n",
    "    \n",
    "#     for img_cluster in [(image_list_cluster0, 0), (image_list_cluster1, 1)]:\n",
    "#         df_images = plot.img_list_to_df(img_cluster[0][:10000])\n",
    "#         png_name = csv_file.split('_')[0] + f'_{img_cluster[1]}.png'\n",
    "#         plot.df_to_img_mosaic(df_images, png_name, bmnist = False, img_names = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "npys_train = []\n",
    "npys_test = []\n",
    "    \n",
    "\n",
    "for idx, csv_file in enumerate(csvs):\n",
    "    image_list_cluster0 = []\n",
    "    image_list_cluster1 = []\n",
    "    df = pd.read_csv(csv_file, index_col=[0])\n",
    "    df = df.iloc[:, 0]\n",
    "\n",
    "    for idx2, element in enumerate(train_dataloaders_class[idx]):\n",
    "        if df[idx2] == 0: #coluna do cluster 0\n",
    "            image_list_cluster1.append((element[2][0], int(element[1].cpu())))\n",
    "        else: \n",
    "            image_list_cluster0.append((element[2][0], int(element[1].cpu())))\n",
    "    \n",
    "    print(len(image_list_cluster0), len(image_list_cluster1))\n",
    "    print((len(image_list_cluster0) + len(image_list_cluster1)))\n",
    "    if len(image_list_cluster0) > len(image_list_cluster1):\n",
    "        npys_train = npys_train + image_list_cluster0\n",
    "        npys_test = npys_test + image_list_cluster1\n",
    "    else:\n",
    "        npys_train = npys_train + image_list_cluster1\n",
    "        npys_test = npys_test + image_list_cluster0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805205cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(npys_train), len(npys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/places8_domino_testset.npy', npys_test)\n",
    "np.save('outputs/places8_domino_trainset.npy', npys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb884fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PACS\n",
    "# for idx, csv_file in enumerate(csvs):\n",
    "#     df = pd.read_csv(csv_file, index_col=[0])\n",
    "#     df_numpy = df.to_numpy()\n",
    "#     image_list_cluster0 = []\n",
    "#     image_list_cluster1 = []\n",
    "#     image_list_cluster2 = []\n",
    "#     image_list_cluster3 = []\n",
    "#     counter = 0\n",
    "#     for idx2, element in enumerate(dataloader): # element = img, label, img_path, domain\n",
    "#         label = element[1]\n",
    "#         if idx == int(label):\n",
    "#             # index of the cluster column\n",
    "#             selected_cluster = int(np.where(df_numpy[counter] == 1)[0])\n",
    "#             if selected_cluster == 0: # belongs to cluster 0\n",
    "#                 image_list_cluster0.append(plot.img_reshape(element[2][0], 64)) # imgpath, img_size\n",
    "#             elif selected_cluster ==1:\n",
    "#                 image_list_cluster1.append(plot.img_reshape(element[2][0], 64)) # imgpath, img_size\n",
    "#             elif selected_cluster ==2:\n",
    "#                 image_list_cluster2.append(plot.img_reshape(element[2][0], 64)) # imgpath, img_size\n",
    "#             else: \n",
    "#                 image_list_cluster3.append(plot.img_reshape(element[2][0], 64)) # imgpath, img_size\n",
    "#             counter += 1\n",
    "    \n",
    "#     for img_cluster in [(image_list_cluster0, 0), (image_list_cluster1,1),\n",
    "#                                        (image_list_cluster2,2), (image_list_cluster3,3)]:\n",
    "#         df_images = plot.img_list_to_df(img_cluster[0])\n",
    "#         png_name = f'outputs/{datasetname}_' + csv_file.split('_')[1] + f'_cluster{img_cluster[1]}.png'\n",
    "#         plot.df_to_img_mosaic(df_images, png_name, bmnist = False, img_names = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76107328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
